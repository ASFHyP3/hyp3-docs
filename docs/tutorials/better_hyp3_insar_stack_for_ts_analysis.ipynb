{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20494ef",
   "metadata": {},
   "source": [
    "# Time series analysis with HyP3 and MintPy\n",
    "\n",
    "This notebook walks through performing a time-series analysis of the 2019 Ridgecrest, CA earthquake with On Demand InSAR products from the Alaska Satellite facility and MintPy. We'll:\n",
    "\n",
    "1. Use the [ASF Search Python package](https://docs.asf.alaska.edu/asf_search/basics/) to:\n",
    "   - Search ASF's catalog for Sentinel-1 SAR products covering the [Ridgecrest earthquake](https://earthquake.usgs.gov/storymap/index-ridgecrest.html)\n",
    "   - Select a reference scene to generate a baseline stack\n",
    "   - Select a [short baseline subset (SBAS)](https://docs.asf.alaska.edu/vertex/sbas/) of scene pairs for InSAR processing\n",
    "\n",
    "\n",
    "2. Use the [HyP3 Python SDK](https://hyp3-docs.asf.alaska.edu/using/sdk/) to:\n",
    "   - Request On Demand InSAR products from ASF HyP3\n",
    "   - Download the InSAR products when they are done processing\n",
    "\n",
    "\n",
    "3. Use [GDAL](https://gdal.org/api/index.html#python-api) and [MintPy](https://mintpy.readthedocs.io/en/latest/) to:\n",
    "   - Prepare the InSAR products for MintPy\n",
    "   - perform a time-series analysis with MintPy\n",
    "   \n",
    "---\n",
    "\n",
    "**Note:** This notebook does assume you have some familiarity with InSAR processing with MintPy already, and is a minimal example without much context or explanations. If you're new to InSAR and MintPy, I suggest checking out:\n",
    "* our [InSAR on Demand Story Map](https://storymaps.arcgis.com/stories/68a8a3253900411185ae9eb6bb5283d3)\n",
    "\n",
    "\n",
    "* [OpenSARlab's](https://opensarlab-docs.asf.alaska.edu/) highly detailed walkthrough of using HyP3 + MintPy via these notebooks:\n",
    "  * [Prepare a HyP3 InSAR Stack for MintPy](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb)\n",
    "  * [MintPy Time-series Analysis](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/MintPy_Time_Series_From_Prepared_Data_Stack.ipynb)\n",
    "  \n",
    "    Note: While these notebooks make some assumptions you're working in OpenSARlab, you can run these \n",
    "    notebooks outside OpenSARlab by creating [this conda environment](https://github.com/ASFOpenSARlab/opensarlab-envs/blob/main/Environment_Configs/insar_analysis_env.yml)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6e353",
   "metadata": {},
   "source": [
    "## 0. Initial Setup\n",
    "\n",
    "To run this notebook, you'll need a conda environment with the required dependencies. You can set up a new environment (recommended) and run the jupyter server like:\n",
    "```shell\n",
    "conda create -n hyp3-mintpy python>=3.10 asf_search hyp3_sdk \"mintpy>=1.5.2\" pandas jupyter ipympl\n",
    "\n",
    "conda activate hyp3-mintpy\n",
    "jupyter notebook hyp3_insar_stack_for_ts_analysis.ipynb\n",
    "```\n",
    "Or, install these dependencies into your own environment:\n",
    "```shell\n",
    "conda install hyp3-mintpy python>=3.10 asf_search hyp3_sdk \"mintpy>=1.5.2\" pandas jupyter ipympl\n",
    "\n",
    "jupyter notebook hyp3_insar_stack_for_ts_analysis.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33543149",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa17bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dateutil.parser import parse as parse_date\n",
    "\n",
    "project_name = '2019_ridgecrest_stac'\n",
    "work_dir = Path.cwd() / project_name\n",
    "stac_dir = work_dir / 'stac'\n",
    "\n",
    "stack_start = parse_date('2019-06-10 00:00:00Z')\n",
    "stack_end = parse_date('2019-07-21 00:00:00Z')\n",
    "max_temporal_baseline = 13  # days\n",
    "\n",
    "mintpy_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62c544",
   "metadata": {},
   "source": [
    "## 1. Select InSAR pairs with ASF Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asf_search as asf\n",
    "import pandas as pd\n",
    "\n",
    "search_results = asf.geo_search(\n",
    "    platform=asf.PLATFORM.SENTINEL1,\n",
    "    intersectsWith='POINT(-117.599330 35.769500)',\n",
    "    start='2019-06-10',\n",
    "    end='2019-07-21',\n",
    "    processingLevel=asf.PRODUCT_TYPE.SLC,\n",
    "    beamMode=asf.BEAMMODE.IW,\n",
    "    flightDirection=asf.FLIGHT_DIRECTION.ASCENDING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ccdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = asf.baseline_search.stack_from_product(search_results[-1])\n",
    "\n",
    "columns = list(baseline_results[0].properties.keys()) + ['geometry']\n",
    "data = [list(scene.properties.values()) + [scene.geometry] for scene in baseline_results]\n",
    "\n",
    "stack = pd.DataFrame(data, columns=columns)\n",
    "stack['startTime'] = stack.startTime.apply(parse_date)\n",
    "\n",
    "stack = stack.loc[(stack_start <= stack.startTime) & (stack.startTime <= stack_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbas_pairs = set()\n",
    "\n",
    "for reference, rt in stack.loc[::-1, ['sceneName', 'temporalBaseline']].itertuples(index=False):\n",
    "    secondaries = stack.loc[\n",
    "        (stack.sceneName != reference) & (stack.temporalBaseline - rt <= max_temporal_baseline) & (stack.temporalBaseline - rt > 0)\n",
    "    ]\n",
    "    for secondary in secondaries.sceneName:\n",
    "        sbas_pairs.add((reference, secondary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c5b0b",
   "metadata": {},
   "source": [
    "## 2. Request On Demand InSAR products from ASF HyP3\n",
    "\n",
    "Use your [NASA Earthdata login](https://urs.earthdata.nasa.gov/) to connect to [ASF HyP3](https://hyp3-docs.asf.alaska.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "\n",
    "\n",
    "hyp3 = sdk.HyP3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dec3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = sdk.Batch()\n",
    "for reference, secondary in sbas_pairs:\n",
    "    jobs += hyp3.submit_insar_job(reference, secondary, name=project_name, include_dem=True, include_look_vectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b82d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = hyp3.watch(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = hyp3.find_jobs(name=project_name, user_id='ffwilliams2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58a0ae-126e-4627-9d55-a69d291504e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyp3_sdk import stac\n",
    "\n",
    "stac.create_stac_collection(jobs, stac_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f5833-038a-418c-a9e4-23957e2307ba",
   "metadata": {},
   "source": [
    "## 3. View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42690c7-510f-4cd1-970d-7b191ecfc8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "from hyp3_sdk import load\n",
    "\n",
    "\n",
    "collection = pystac.Collection.from_file(stac_dir / 'collection.json')\n",
    "items = list(collection.get_all_items())\n",
    "dataset = load.create_xarray_dataset(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23103b-4c8a-425e-afe4-d50e91d43fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac2623-b72e-4f39-8778-c1885a9f6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_ds = dataset[dataset.coords['id'] == 'S1BB_20190628T014958_20190710T014959_VVP012_INT80_G_ueF_006C'].sel(band='unw_phase')\n",
    "eq_ds = eq_ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f13e70-21db-47d4-983c-d1cfaabe1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "\n",
    "\n",
    "m = leafmap.Map()\n",
    "unw_image = leafmap.array_to_image(eq_ds.to_numpy(), cellsize=eq_ds.transform[0], crs=eq_ds.crs, transform=eq_ds.transform)\n",
    "m.add_raster(unw_image, colormap='coolwarm', layer_name='Unwrap')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c68c6f8-6d58-4176-83cc-79e62c8a1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj.transformer import Transformer\n",
    "from shapely.geometry import Polygon, shape\n",
    "\n",
    "\n",
    "def get_bbox(map, epsg):\n",
    "    features = m.draw_features\n",
    "    if len(features) > 1:\n",
    "        raise ValueError('Only 1 feature can be used. Remove all features from map and start again.')\n",
    "    polygon = Polygon(shape(features[0]['geometry']))\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    transformer = Transformer.from_crs('EPSG:4326', f'EPSG:{epsg}', always_xy=True)\n",
    "    (minx, maxx), (miny, maxy) = transformer.transform([minx, maxx], [miny, maxy])\n",
    "    return [round(coord) for coord in (minx, maxx, miny, maxy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d932cd4-0ce9-43de-93e3-bcf7c3cadf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bbox(m, dataset.epsg.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87385631",
   "metadata": {},
   "source": [
    "## 4. Run MintPy time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe008273-aeda-481f-b039-b6e29db171d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from hyp3_sdk import load\n",
    "\n",
    "load.create_mintpy_inputs(stac_dir / 'collection.json', subset_geo=get_bbox(m, dataset.epsg.item()), mintpy_dir=mintpy_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ebed3-4d2b-4491-9b81-518b369c30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mintpy_config = mintpy_dir / 'mintpy_config.cfg'\n",
    "mintpy_config.write_text(\n",
    "    f\"\"\"\n",
    "mintpy.load.processor = hyp3\n",
    "##---------misc:\n",
    "mintpy.plot = no\n",
    "mintpy.network.coherenceBased = no\n",
    "mintpy.troposphericDelay.method = no\n",
    "mintpy.reference.date = 20190610\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir {mintpy_dir} --start modify_network {mintpy_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e866ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.cli import view, tsview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2635c7-bfdb-411a-bfa4-b6789005772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view.main([f'{mintpy_dir}/velocity.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6172aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsview.main([f'{mintpy_dir}/timeseries.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a8713-877b-4b52-acc6-9bc20d79decf",
   "metadata": {},
   "source": [
    "## 5. Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ff439-b071-4784-82e5-25314f5d2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -shm 2019_ridgecrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4cb10-3298-45bb-956a-237cc987d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -shm 2019_ridgecrest/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4101fc4-ab3e-4384-9c45-2651bf70ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "3842 - 3622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cc569-e249-4d68-956a-004b6212147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -shm 2019_ridgecrest_stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420d400-1bbf-4e02-a68f-419409727296",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_percent = 260 / 3842\n",
    "f'The STAC method produces the same result, but creates only {data_percent:.1%} of the data!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c7294-bd62-413f-a047-b15530dc4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "round((3842 / 11) * 250 / 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30dfc0-bda4-4e95-b3b3-425087564c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "round((260 / 11) * 250 / 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408564f7-70ef-4439-b08d-04f60110f6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
