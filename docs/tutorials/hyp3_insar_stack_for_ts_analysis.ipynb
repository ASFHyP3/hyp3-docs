{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e637fad",
   "metadata": {},
   "source": [
    "# Time series analysis with HyP3 and MintPy\n",
    "\n",
    "This notebook walks through performing a time-series analysis of the 2019 Ridgecrest, CA earthquake with On Demand InSAR products from the Alaska Satellite facility and MintPy. We'll:\n",
    "\n",
    "1. Use the [ASF Search Python package](https://docs.asf.alaska.edu/asf_search/basics/) to:\n",
    "   - Search ASF's catalog for Sentinel-1 SAR products covering the [Ridgecrest](https://earthquake.usgs.gov/storymap/index-ridgecrest.html)\n",
    "   - Select a reference scene to generate a baseline stack\n",
    "   - Select a [short baseline subset (SBAS)](https://docs.asf.alaska.edu/vertex/sbas/) of scene pairs for InSAR processing\n",
    "\n",
    "\n",
    "2. Use the [HyP3 Python SDK](https://hyp3-docs.asf.alaska.edu/using/sdk/) to:\n",
    "   - Request On Demand InSAR products from ASF HyP3\n",
    "   - Download the InSAR products when they are done processing\n",
    "\n",
    "\n",
    "3. Use [GDAL](https://gdal.org/api/index.html#python-api) and [MintPy](https://mintpy.readthedocs.io/en/latest/) to:\n",
    "   - Prepare the InSAR products for MintPy\n",
    "   - perform a time-series analysis with MintPy\n",
    "   \n",
    "---\n",
    "\n",
    "**Note:** This notebook does assume you have some familiarity with InSAR processing with MintPy already, and is a minimal example without much context or explanations. If you're new to InSAR and MintPy, I suggest checking out:\n",
    "* our [InSAR on Demand story map](https://storymaps.arcgis.com/stories/68a8a3253900411185ae9eb6bb5283d3)\n",
    "\n",
    "\n",
    "* [OpenSARlab's](https://opensarlab-docs.asf.alaska.edu/) highly detailed walkthrough of using HyP3 + MintPy via these notebooks:\n",
    "  * [Prepare a HyP3 InSAR Stack for MintPy](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb)\n",
    "  * [MintPy Time-series Analysis](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/MintPy_Time_Series_From_Prepared_Data_Stack.ipynb)\n",
    "  \n",
    "    Note: While these notebooks make some assumptions you're working in OpenSARlab, you can run these \n",
    "    notebooks outside OpenSARlab by creating [this conda environment](https://github.com/ASFOpenSARlab/opensarlab-envs/blob/main/Environment_Configs/insar_analysis_env.yml)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e7768",
   "metadata": {},
   "source": [
    "## 0. Initial Setup\n",
    "\n",
    "To run this notebook, you'll need a conda environment with the required dependencies. You can set up a new environment (recommended) and run the jupyter server like:\n",
    "```shell\n",
    "conda create -n hyp3-mintpy python=3.8 asf_search hyp3_sdk \"mintpy>=1.3.2\" pandas jupyter ipympl\n",
    "\n",
    "conda activate hyp3-mintpy\n",
    "jupyter notebook hyp3_insar_stack_for_ts_analysis.ipynb\n",
    "```\n",
    "Or, install these dependencies into your own environment:\n",
    "```shell\n",
    "conda install hyp3-mintpy python=3.8 asf_search hyp3_sdk \"mintpy>=1.3.2\" pandas jupyter ipympl\n",
    "\n",
    "jupyter notebook hyp3_insar_stack_for_ts_analysis.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6cc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from dateutil.parser import parse as parse_date\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "import asf_search as asf\n",
    "import hyp3_sdk as sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6208b",
   "metadata": {},
   "source": [
    "### define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersect_rectangle_geotiffs(filelist):\n",
    "    '''\n",
    "    :param data_dir: data directory storing the hyp3 products.\n",
    "    :process get the smallest overlap retangular area to clip the geotiff files.\n",
    "    :return:\n",
    "    '''\n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in filelist]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]\n",
    "\n",
    "\n",
    "def prepare_hyp3_product(data_dir):\n",
    "    filelist = glob.glob(f\"{data_dir}/*/*_dem.tif\")\n",
    "    insect_box = get_intersect_rectangle_geotiffs(filelist)\n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    list_product_dirs = [f.path for f in os.scandir(data_dir) if f.is_dir()]\n",
    "\n",
    "    for product_dir in list_product_dirs:\n",
    "        for file_suffix in files_for_mintpy:\n",
    "            product_dir = Path(product_dir)\n",
    "            src_file = product_dir / f'{product_dir.name}{file_suffix}'\n",
    "            dst_file = product_dir / f'{src_file.stem}_clipped{src_file.suffix}'\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(src_file), projWin=insect_box)\n",
    "\n",
    "\n",
    "def create_sbas_pairs_file(intersect_point, date_range, sbas_pairs_file):\n",
    "    '''\n",
    "    :param intersect_ponit:(longitude, latitude)\n",
    "    :param date_range: ('yyyy-mm-dd','yyyy-mm-dd')\n",
    "    :param sbas_pairs_file: file name to store the sbas_pairs\n",
    "    :return: a set of tuples, each tuple includes a pair of file names\n",
    "    '''\n",
    "\n",
    "    point = f'POINT({intersect_point[0]} {intersect_point[1]})'\n",
    "\n",
    "    search_results = asf.geo_search(\n",
    "        platform=asf.SENTINEL1,\n",
    "        intersectsWith=point,\n",
    "        start=date_range[0],\n",
    "        end=date_range[1],\n",
    "        processingLevel=asf.SLC,\n",
    "        beamMode=asf.IW,\n",
    "        flightDirection=asf.ASCENDING,\n",
    "    )\n",
    "\n",
    "    baseline_results = asf.baseline_search.stack_from_product(search_results[-1])\n",
    "\n",
    "    columns = list(baseline_results[0].properties.keys()) + ['geometry', ]\n",
    "    data = [list(scene.properties.values()) + [scene.geometry, ] for scene in baseline_results]\n",
    "\n",
    "    stack = pd.DataFrame(data, columns=columns)\n",
    "    stack['startTime'] = stack.startTime.apply(parse_date)\n",
    "\n",
    "    stack = stack.loc[(stack_start <= stack.startTime) & (stack.startTime <= stack_end)]\n",
    "\n",
    "    sbas_pairs = set()\n",
    "    for reference, rt in stack.loc[::-1, ['sceneName', 'temporalBaseline']].itertuples(index=False):\n",
    "        secondaries = stack.loc[\n",
    "            (stack.sceneName != reference)\n",
    "            & (stack.temporalBaseline - rt <= max_temporal_baseline)\n",
    "            & (stack.temporalBaseline - rt > 0)\n",
    "        ]\n",
    "        for secondary in secondaries.sceneName:\n",
    "            sbas_pairs.add((reference, secondary))\n",
    "\n",
    "    with open(sbas_pairs_file, 'w') as f:\n",
    "        for t in sbas_pairs:\n",
    "            f.write(f\"{t[0]},{t[1]}\\n\")\n",
    "\n",
    "    return sbas_pairs_file\n",
    "\n",
    "\n",
    "def get_sbas_pairs_set(sbas_pairs_file):\n",
    "    sbas_pairs = set()\n",
    "    with open(sbas_pairs_file) as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            sbas_pairs.add((line.split(\",\")[0], line.split(\",\")[1]))\n",
    "            \n",
    "    return sbas_pairs\n",
    "\n",
    "\n",
    "def download_products_by_sbas_pairs(sbas_pairs_file, project_name, data_dir):\n",
    "    '''\n",
    "    :param sbas_pairs: a set of tuples, where each tuple include a pair of\n",
    "    :proecess: submit the INSAR jobs based on the pairs defined in the sbas_pairs to hyp3 server,\n",
    "    download the hyp3 products to the data_dir.\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    hyp3 = sdk.HyP3(prompt=True)\n",
    "\n",
    "    jobs = sdk.Batch()\n",
    "    sbas_pairs = get_sbas_pairs_set(sbas_pairs_file)\n",
    "    for reference, secondary in sbas_pairs:\n",
    "        jobs += hyp3.submit_insar_job(reference, secondary, name=project_name,\n",
    "                                      include_dem=True, include_look_vectors=True)\n",
    "\n",
    "    jobs = hyp3.find_jobs(name=project_name)\n",
    "\n",
    "    jobs = hyp3.watch(jobs)\n",
    "\n",
    "    insar_products = jobs.download_files(data_dir)\n",
    "\n",
    "    insar_products = [sdk.util.extract_zipped_product(ii) for ii in insar_products]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8584cc",
   "metadata": {},
   "source": [
    "### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = '2019_ridgecrest'\n",
    "project_home = Path('/media/jzhu4/data/hyp3-mintpy')\n",
    "work_dir = project_home / project_name\n",
    "data_dir = work_dir / 'data'\n",
    "\n",
    "stack_start = parse_date('2019-06-10')\n",
    "stack_end = parse_date('2019-07-21')\n",
    "max_temporal_baseline = 12 #days\n",
    "\n",
    "if not os.path.isdir(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "    print('Create directory: {}'.format(work_dir))\n",
    "    \n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print('Create directory: {}'.format(data_dir))\n",
    "    \n",
    "os.chdir(work_dir)\n",
    "print('Go to work directory: {}'.format(work_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcae47c",
   "metadata": {},
   "source": [
    "## 1. Select InSAR pairs with ASF Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_point = (-117.599330, 35.769500)\n",
    "\n",
    "date_range=('2019-06-10', '2019-07-21')\n",
    "\n",
    "sbas_pairs_file = work_dir / 'sbas_pairs.dat'\n",
    "\n",
    "sbas_pairs_file = create_sbas_pairs_file(intersect_point, date_range, sbas_pairs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sbas pairs are stores at {os.path.abspath(sbas_pairs_file)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb339c62",
   "metadata": {},
   "source": [
    "## 2. Request On Demand InSAR products from ASF HyP3\n",
    "\n",
    "Use your [NASA Earthdata login](https://urs.earthdata.nasa.gov/) to connect to [ASF HyP3](https://hyp3-docs.asf.alaska.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_products_by_sbas_pairs(sbas_pairs_file, project_name, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76721eac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"hyp3 products are stored at {os.path.abspath(data_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61540913",
   "metadata": {},
   "source": [
    "## 3. Time-series Analysis with MintPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc1834",
   "metadata": {},
   "source": [
    "### 3.1 cut off the geotiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_hyp3_product(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b8eaa",
   "metadata": {},
   "source": [
    "### 3.2 create the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75eb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mintpy_config = work_dir / 'mintpy_config.txt'\n",
    "mintpy_config.write_text(\n",
    "f\"\"\"\n",
    "mintpy.load.processor        = hyp3\n",
    "##---------interferogram datasets:\n",
    "mintpy.load.unwFile          = {data_dir}/*/*_unw_phase_clipped.tif\n",
    "mintpy.load.corFile          = {data_dir}/*/*_corr_clipped.tif\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile          = {data_dir}/*/*_dem_clipped.tif\n",
    "mintpy.load.incAngleFile     = {data_dir}/*/*_lv_theta_clipped.tif\n",
    "mintpy.load.azAngleFile      = {data_dir}/*/*_lv_phi_clipped.tif\n",
    "mintpy.load.waterMaskFile    = {data_dir}/*/*_water_mask_clipped.tif\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f12d6",
   "metadata": {},
   "source": [
    "### 3.3 run mintpy to do time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --dir {work_dir} {mintpy_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59860b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mintpy import view, tsview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feefee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main([f'{work_dir}/velocity.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd558571",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsview.main([f'{work_dir}/timeseries.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fabd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyp3-mintpy",
   "language": "python",
   "name": "hyp3-mintpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
