{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20494ef",
   "metadata": {},
   "source": [
    "# Merge HyP3 ISCE2 burst InSAR products\n",
    "\n",
    "This notebook demonstrates the `merge_tops_burst` workflow in the hyp3-isce2 plugin. The workflow merges multiple Burst InSAR Products. The input of the workflow is the directory that includes multiple HyP3-ISCE2 Burst InSAR Products.These products are created by HyP3-ISCE2 plugin. How to create HyP3 Burst InSAR Product is described in detail in the notebook [hyp3_isce2_burst_stack_for_ts_analysis](https://github.com/ASFHyP3/hyp3-docs/blob/main/docs/tutorials/hyp3_isce2_burst_stack_for_ts_analysis.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "**Note:** This notebook does assume you have some familiarity with InSAR processing with MintPy already, and is a minimal example without much context or explanations. If you're new to InSAR and MintPy, we suggest checking out the following resources. Note that some of these resources may be specific to our InSAR GAMMA products, so you may need to adapt them for use with our ISCE2-based burst InSAR products.\n",
    "\n",
    "* Our [Burst Data Download Story Map](https://storymaps.arcgis.com/stories/88c8fe67933340779eddef212d76b8b8)\n",
    "\n",
    "* Our [product guide](https://hyp3-docs.asf.alaska.edu/guides/burst_insar_product_guide/) for burst InSAR products\n",
    "\n",
    "* Our [GitHub repository](https://github.com/asfhyp3/hyp3-isce2) containg the workflow used to create burst InSAR products\n",
    "\n",
    "* Our [InSAR on Demand Story Map](https://storymaps.arcgis.com/stories/68a8a3253900411185ae9eb6bb5283d3)\n",
    "\n",
    "* [OpenSARlab's](https://opensarlab-docs.asf.alaska.edu/) highly detailed walkthrough of using HyP3 + MintPy via these notebooks:\n",
    "  * [Prepare a HyP3 InSAR Stack for MintPy](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/Prepare_HyP3_InSAR_Stack_for_MintPy.ipynb)\n",
    "  * [MintPy Time-series Analysis](https://nbviewer.org/github/ASFOpenSARlab/opensarlab-notebooks/blob/master/SAR_Training/English/Master/MintPy_Time_Series_From_Prepared_Data_Stack.ipynb)\n",
    "  \n",
    "    Note: While these notebooks make some assumptions you're working in OpenSARlab, you can run these \n",
    "    notebooks outside OpenSARlab by creating [this conda environment](https://github.com/ASFOpenSARlab/opensarlab-envs/blob/main/Environment_Configs/insar_analysis_env.yml)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6e353",
   "metadata": {},
   "source": [
    "## 0. Initial Setup\n",
    "To run this notebook, you will need a local copy of the HyP3-ISCE2 GitHub repository and to set up a conda environment with the required dependencies. In your terminal, you can do this with the following commnads:\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/ASFHyP3/hyp3-isce2.git\n",
    "cd hyp3-isce2\n",
    "mamba env create -f environment.yml\n",
    "mamba activate hyp3-isce2\n",
    "python -m pip install -e .\n",
    "mamba install -c conda-forge pandas jupyter ipympl\n",
    "jupyter notebook hyp3_isce2_burst_merge.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f093a40806f3ca5",
   "metadata": {},
   "source": [
    "This workflow requires an Earth Data Cloud login. If you haven't yet, you can make an [account for free](https://urs.earthdata.nasa.gov/users/new) and set up a `.netrc` file in your home directory with your personal username and password.\n",
    "\n",
    "```shell\n",
    "echo ‘machine urs.earthdata.nasa.gov login $USERNAME password $PASSWORD’ >> ~/.netrc \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62c544",
   "metadata": {},
   "source": [
    "## 1. Prepare the input data\n",
    "Before using the [HyP3-ISCE2 merge burst workflow](https://hyp3-docs.asf.alaska.edu/guides/burst_insar_product_guide/#merge-sentinel-1-burst-insar-products), we must double check our data are prepared so that all Bursts:\n",
    "- Have the same reference and secondary dates\n",
    "- Have the same polarization\n",
    "- Have the same multilooking\n",
    "- Be from the same relative orbit\n",
    "- Be contiguous\n",
    "\n",
    "We will set up a directory to store input data and output merge products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118061a10128fa80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T00:34:40.820586Z",
     "start_time": "2024-02-12T00:34:40.813374Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_name = 'merge_burst_products'\n",
    "work_dir = Path.cwd() / project_name\n",
    "data_dir = work_dir / 'data'\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2656ab8e17fd00e5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Copy over unzipped folders that contain all outputs from HyP3 Burst processing to the data_dir directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c5b0b",
   "metadata": {},
   "source": [
    "## 2. Merge the products using hyp3-isce2 merge_tops_burst workflow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dec3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "cur_dir = Path.cwd()\n",
    "os.chdir(work_dir)\n",
    "\n",
    "cmd = ['python', '-m', 'hyp3_isce2', '++process', 'merge_tops_bursts', f'{str(data_dir)}', '--apply-water-mask', 'True']\n",
    "subprocess.run(cmd)\n",
    "\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b717cb5-2895-4c1b-abfb-6e597e648d23",
   "metadata": {},
   "source": [
    "## 3. Display the merged product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38d8de-9bcf-4544-b9d5-682dd44932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "tifs = [f for f in work_dir.glob(\"*/*.tif\")]\n",
    "for tif in tifs: \n",
    "    if not tif.name.split('_')[2]:\n",
    "        src = rasterio.open(tif)\n",
    "        show(src, title=tif.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7eedce43cd54c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tifs = [f for f in work_dir.glob(\"*/*.tif\")]\n",
    "\n",
    "f, axs = plt.subplots(len(tifs), figsize=(6,6))\n",
    "i = 0 \n",
    "for tif in tifs: \n",
    "    if not tif.name.split('_')[2]:\n",
    "        ds = gdal.Open(str(tif))\n",
    "        merged_bursts = np.ma.masked_equal(ds.GetRasterBand(1).ReadAsArray(), 0)\n",
    "        \n",
    "    axs[i].imshow(merged_bursts)\n",
    "    axs[i].set_title(tif.name)\n",
    "\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "    plt.tight_layout()\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
